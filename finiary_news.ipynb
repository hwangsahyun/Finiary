{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d90598e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: trafilatura in /opt/anaconda3/lib/python3.12/site-packages (2.0.0)\n",
      "Requirement already satisfied: feedparser in /opt/anaconda3/lib/python3.12/site-packages (6.0.12)\n",
      "Collecting apscheduler\n",
      "  Downloading apscheduler-3.11.2-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: pydantic in /opt/anaconda3/lib/python3.12/site-packages (2.11.7)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/lib/python3.12/site-packages (from trafilatura) (2025.8.3)\n",
      "Requirement already satisfied: charset_normalizer>=3.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from trafilatura) (3.4.4)\n",
      "Requirement already satisfied: courlan>=1.3.2 in /opt/anaconda3/lib/python3.12/site-packages (from trafilatura) (1.3.2)\n",
      "Requirement already satisfied: htmldate>=1.9.2 in /opt/anaconda3/lib/python3.12/site-packages (from trafilatura) (1.9.4)\n",
      "Requirement already satisfied: justext>=3.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from trafilatura) (3.0.2)\n",
      "Requirement already satisfied: lxml>=5.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from trafilatura) (6.0.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in /opt/anaconda3/lib/python3.12/site-packages (from trafilatura) (2.2.2)\n",
      "Requirement already satisfied: sgmllib3k in /opt/anaconda3/lib/python3.12/site-packages (from feedparser) (1.0.0)\n",
      "Requirement already satisfied: tzlocal>=3.0 in /opt/anaconda3/lib/python3.12/site-packages (from apscheduler) (5.3.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic) (4.15.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic) (0.4.0)\n",
      "Requirement already satisfied: babel>=2.16.0 in /opt/anaconda3/lib/python3.12/site-packages (from courlan>=1.3.2->trafilatura) (2.17.0)\n",
      "Requirement already satisfied: tld>=0.13 in /opt/anaconda3/lib/python3.12/site-packages (from courlan>=1.3.2->trafilatura) (0.13.1)\n",
      "Requirement already satisfied: dateparser>=1.1.2 in /opt/anaconda3/lib/python3.12/site-packages (from htmldate>=1.9.2->trafilatura) (1.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.9.0.post0 in /opt/anaconda3/lib/python3.12/site-packages (from htmldate>=1.9.2->trafilatura) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2024.2 in /opt/anaconda3/lib/python3.12/site-packages (from dateparser>=1.1.2->htmldate>=1.9.2->trafilatura) (2025.2)\n",
      "Requirement already satisfied: regex>=2024.9.11 in /opt/anaconda3/lib/python3.12/site-packages (from dateparser>=1.1.2->htmldate>=1.9.2->trafilatura) (2026.1.15)\n",
      "Requirement already satisfied: lxml_html_clean in /opt/anaconda3/lib/python3.12/site-packages (from lxml[html_clean]>=4.4.2->justext>=3.0.1->trafilatura) (0.4.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.9.0.post0->htmldate>=1.9.2->trafilatura) (1.16.0)\n",
      "Downloading apscheduler-3.11.2-py3-none-any.whl (64 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m64.4/64.4 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: apscheduler\n",
      "Successfully installed apscheduler-3.11.2\n"
     ]
    }
   ],
   "source": [
    "!pip install trafilatura feedparser apscheduler pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff69f201",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import sqlite3\n",
    "import feedparser\n",
    "import trafilatura\n",
    "from datetime import datetime\n",
    "from apscheduler.schedulers.background import BackgroundScheduler\n",
    "from pydantic import BaseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81419123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 1. í™˜ê²½ ì„¤ì • (Configuration)\n",
    "# ==========================================\n",
    "DB_FILE = \"finiary.db\"           # ë°ì´í„°ê°€ ì €ì¥ë  DB íŒŒì¼ëª…\n",
    "UPDATE_INTERVAL_MINUTES = 1     # ë‰´ìŠ¤ í™•ì¸ ì£¼ê¸° (ë¶„)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b87034e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 2. ë°ì´í„° ëª¨ë¸ (Data Structure)\n",
    "# ==========================================\n",
    "class StockNews(BaseModel):\n",
    "    title: str\n",
    "    link: str\n",
    "    source: str\n",
    "    pub_date: str\n",
    "    content: str  # ë³¸ë¬¸ ì „ì²´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46367fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 3. Finiary ìˆ˜ì§‘ ì—”ì§„ (Core Logic)\n",
    "# ==========================================\n",
    "class FiniaryEngine:\n",
    "    def __init__(self):\n",
    "        # ì£¼ì‹/ì‹œí™©/ì¦ê¶Œ ì „ë¬¸ RSS ì†ŒìŠ¤\n",
    "        self.rss_sources = {\n",
    "            \"í•œêµ­ê²½ì œ(ì¦ê¶Œ)\": \"https://rss.hankyung.com/feed/market\",\n",
    "            \"ë§¤ì¼ê²½ì œ(ì¦ê¶Œ)\": \"https://www.mk.co.kr/rss/50300009/\",\n",
    "            \"ì„œìš¸ê²½ì œ(ì¦ê¶Œ)\": \"https://www.sedaily.com/RSS/Stock\",\n",
    "            \"ì´ë°ì¼ë¦¬(ì¦ê¶Œ)\": \"https://rss.edaily.co.kr/stock_news.xml\",\n",
    "            \"ì•„ì‹œì•„ê²½ì œ(ì¦ê¶Œ)\": \"https://rss.asiae.co.kr/stock.xml\"\n",
    "        }\n",
    "        self.init_database()\n",
    "\n",
    "    def init_database(self):\n",
    "        \"\"\"DB í…Œì´ë¸”ì´ ì—†ìœ¼ë©´ ìƒì„±\"\"\"\n",
    "        try:\n",
    "            conn = sqlite3.connect(DB_FILE)\n",
    "            cursor = conn.cursor()\n",
    "            # link ì»¬ëŸ¼ì— UNIQUE ì œì•½ì¡°ê±´ì„ ê±¸ì–´ ì¤‘ë³µ ì €ì¥ì„ ì›ì²œ ì°¨ë‹¨\n",
    "            cursor.execute('''\n",
    "                CREATE TABLE IF NOT EXISTS news (\n",
    "                    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                    title TEXT,\n",
    "                    link TEXT UNIQUE,\n",
    "                    source TEXT,\n",
    "                    pub_date TEXT,\n",
    "                    content TEXT,\n",
    "                    ai_summary TEXT,      -- ì¶”í›„ AI ìš”ì•½ ì €ì¥ìš©\n",
    "                    ai_sentiment TEXT,    -- ì¶”í›„ AI í˜¸ì¬/ì•…ì¬ ì €ì¥ìš©\n",
    "                    collected_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    "                )\n",
    "            ''')\n",
    "            conn.commit()\n",
    "            conn.close()\n",
    "            print(f\"âœ… ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì™„ë£Œ: {DB_FILE}\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ DB ì´ˆê¸°í™” ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "    def is_duplicate(self, link):\n",
    "        \"\"\"ì´ë¯¸ ìˆ˜ì§‘í•œ ë‰´ìŠ¤ì¸ì§€ DBì—ì„œ í™•ì¸\"\"\"\n",
    "        conn = sqlite3.connect(DB_FILE)\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute('SELECT 1 FROM news WHERE link = ?', (link,))\n",
    "        exists = cursor.fetchone()\n",
    "        conn.close()\n",
    "        return exists is not None\n",
    "\n",
    "    def crawl_full_body(self, url):\n",
    "        \"\"\"ë§í¬ íƒ€ê³  ë“¤ì–´ê°€ì„œ ë³¸ë¬¸ ì „ì²´ ì¶”ì¶œ (Trafilatura ì‚¬ìš©)\"\"\"\n",
    "        try:\n",
    "            downloaded = trafilatura.fetch_url(url)\n",
    "            if downloaded:\n",
    "                # í‘œ(Table) í¬í•¨, ëŒ“ê¸€ ì œì™¸í•˜ê³  ë³¸ë¬¸ ì¶”ì¶œ\n",
    "                text = trafilatura.extract(downloaded, include_tables=True, include_comments=False)\n",
    "                return text\n",
    "            return None\n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "    def save_to_db(self, news: StockNews):\n",
    "        \"\"\"DBì— ë‰´ìŠ¤ ì €ì¥\"\"\"\n",
    "        try:\n",
    "            conn = sqlite3.connect(DB_FILE)\n",
    "            cursor = conn.cursor()\n",
    "            cursor.execute('''\n",
    "                INSERT OR IGNORE INTO news (title, link, source, pub_date, content)\n",
    "                VALUES (?, ?, ?, ?, ?)\n",
    "            ''', (news.title, news.link, news.source, news.pub_date, news.content))\n",
    "            conn.commit()\n",
    "            conn.close()\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "            return False\n",
    "\n",
    "    def job(self):\n",
    "        \"\"\"ìŠ¤ì¼€ì¤„ëŸ¬ê°€ ì£¼ê¸°ì ìœ¼ë¡œ ì‹¤í–‰í•  ì‘ì—…\"\"\"\n",
    "        print(f\"\\nâ° [ìë™ìˆ˜ì§‘ ì‹œì‘] {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "        new_items_count = 0\n",
    "\n",
    "        for source_name, rss_url in self.rss_sources.items():\n",
    "            # RSS í”¼ë“œ ë¡œë”© (ê°€ë²¼ìš´ ì‘ì—…)\n",
    "            feed = feedparser.parse(rss_url)\n",
    "            \n",
    "            # ìµœì‹ ìˆœìœ¼ë¡œ ë“¤ì–´ì˜¤ë¯€ë¡œ, íš¨ìœ¨ì„ ìœ„í•´ ìƒìœ„ 10ê°œë§Œ ê²€ì‚¬í•´ë„ ì¶©ë¶„\n",
    "            for entry in feed.entries[:10]:\n",
    "                link = entry.link\n",
    "                title = entry.title\n",
    "\n",
    "                # 1. ì¤‘ë³µ ê²€ì‚¬ (DBì— ìˆìœ¼ë©´ ê±´ë„ˆëœ€)\n",
    "                if self.is_duplicate(link):\n",
    "                    continue\n",
    "\n",
    "                print(f\"   ğŸ†• ì‹ ê·œ ë°œê²¬: {title[:20]}...\", end=\"\")\n",
    "\n",
    "                # 2. ë³¸ë¬¸ í¬ë¡¤ë§\n",
    "                content = self.crawl_full_body(link)\n",
    "\n",
    "                # ë³¸ë¬¸ì´ ì—†ê±°ë‚˜ ë„ˆë¬´ ì§§ìœ¼ë©´(ì˜ìƒ/ê´‘ê³ ) ì €ì¥ ì•ˆ í•¨\n",
    "                if not content or len(content) < 200:\n",
    "                    print(\" ğŸš« [Pass: ë³¸ë¬¸ ì§§ìŒ]\")\n",
    "                    continue\n",
    "\n",
    "                # 3. ê°ì²´ ìƒì„± ë° ì €ì¥\n",
    "                news_item = StockNews(\n",
    "                    title=title,\n",
    "                    link=link,\n",
    "                    source=source_name,\n",
    "                    pub_date=entry.get('published', datetime.now().strftime('%Y-%m-%d')),\n",
    "                    content=content\n",
    "                )\n",
    "                \n",
    "                self.save_to_db(news_item)\n",
    "                new_items_count += 1\n",
    "                print(\" âœ… ì €ì¥ ì™„ë£Œ\")\n",
    "\n",
    "                # ì„œë²„ ë¶€í•˜ ë°©ì§€ (0.5ì´ˆ ëŒ€ê¸°)\n",
    "                time.sleep(0.5)\n",
    "\n",
    "        if new_items_count == 0:\n",
    "            print(\"ğŸ’¤ ìƒˆë¡œìš´ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        else:\n",
    "            print(f\"ğŸ‰ ì—…ë°ì´íŠ¸ ì™„ë£Œ! ì´ {new_items_count}ê°œì˜ ìƒˆ ê¸°ì‚¬ë¥¼ ì €ì¥í–ˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "281b36c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì™„ë£Œ: finiary.db\n",
      "\n",
      "â° [ìë™ìˆ˜ì§‘ ì‹œì‘] 2026-01-27 17:40:36\n",
      "ğŸ’¤ ìƒˆë¡œìš´ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "\n",
      "============================================================\n",
      "ğŸš€ Finiary ìˆ˜ì§‘ê¸° ê°€ë™ ì¤‘ (ì£¼ê¸°: 1ë¶„)\n",
      "ğŸ“‚ ë°ì´í„°ë² ì´ìŠ¤: finiary.db\n",
      "ì¢…ë£Œí•˜ë ¤ë©´ Ctrl+Cë¥¼ ëˆ„ë¥´ì„¸ìš”.\n",
      "============================================================\n",
      "\n",
      "â° [ìë™ìˆ˜ì§‘ ì‹œì‘] 2026-01-27 17:41:36\n",
      "ğŸ’¤ ìƒˆë¡œìš´ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "\n",
      "â° [ìë™ìˆ˜ì§‘ ì‹œì‘] 2026-01-27 17:42:36\n",
      "ğŸ’¤ ìƒˆë¡œìš´ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "\n",
      "â° [ìë™ìˆ˜ì§‘ ì‹œì‘] 2026-01-27 17:43:36\n",
      "ğŸ’¤ ìƒˆë¡œìš´ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "\n",
      "â° [ìë™ìˆ˜ì§‘ ì‹œì‘] 2026-01-27 17:44:36\n",
      "ğŸ’¤ ìƒˆë¡œìš´ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "\n",
      "â° [ìë™ìˆ˜ì§‘ ì‹œì‘] 2026-01-27 17:45:36\n",
      "ğŸ’¤ ìƒˆë¡œìš´ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "\n",
      "â° [ìë™ìˆ˜ì§‘ ì‹œì‘] 2026-01-27 17:46:36\n",
      "ğŸ’¤ ìƒˆë¡œìš´ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "\n",
      "â° [ìë™ìˆ˜ì§‘ ì‹œì‘] 2026-01-27 17:47:36\n",
      "ğŸ’¤ ìƒˆë¡œìš´ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "\n",
      "â° [ìë™ìˆ˜ì§‘ ì‹œì‘] 2026-01-27 17:48:36\n",
      "ğŸ’¤ ìƒˆë¡œìš´ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "\n",
      "â° [ìë™ìˆ˜ì§‘ ì‹œì‘] 2026-01-27 17:49:36\n",
      "   ğŸ†• ì‹ ê·œ ë°œê²¬: \"ì…ì§€ë§Œ ì¢‹ë‹¤ë©´ ì‘ì•„ë„ ë¼\" â€¦ í•œê°•... âœ… ì €ì¥ ì™„ë£Œ\n",
      "   ğŸ†• ì‹ ê·œ ë°œê²¬: ê³µê¸‰ëŒ€ì±… ë°œí‘œë„ ì•ˆ ëëŠ”ë° â€¦ ê³¼ì²œÂ·... âœ… ì €ì¥ ì™„ë£Œ\n",
      "ğŸ‰ ì—…ë°ì´íŠ¸ ì™„ë£Œ! ì´ 2ê°œì˜ ìƒˆ ê¸°ì‚¬ë¥¼ ì €ì¥í–ˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "â° [ìë™ìˆ˜ì§‘ ì‹œì‘] 2026-01-27 17:50:36\n",
      "ğŸ’¤ ìƒˆë¡œìš´ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "\n",
      "â° [ìë™ìˆ˜ì§‘ ì‹œì‘] 2026-01-27 17:51:36\n",
      "ğŸ’¤ ìƒˆë¡œìš´ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "\n",
      "â° [ìë™ìˆ˜ì§‘ ì‹œì‘] 2026-01-27 17:52:36\n",
      "ğŸ’¤ ìƒˆë¡œìš´ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "ğŸ›‘ ìˆ˜ì§‘ê¸°ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 4. ì‹¤í–‰ (Execution)\n",
    "# ==========================================\n",
    "if __name__ == \"__main__\":\n",
    "    # 1. ì—”ì§„ ì´ˆê¸°í™”\n",
    "    engine = FiniaryEngine()\n",
    "    \n",
    "    # 2. ìŠ¤ì¼€ì¤„ëŸ¬ ì„¤ì • (ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰)\n",
    "    scheduler = BackgroundScheduler()\n",
    "    scheduler.add_job(engine.job, 'interval', minutes=UPDATE_INTERVAL_MINUTES)\n",
    "    scheduler.start()\n",
    "\n",
    "    # 3. ìµœì´ˆ 1íšŒ ì¦‰ì‹œ ì‹¤í–‰ (ê¸°ë‹¤ë¦¬ì§€ ì•Šê³  ë°”ë¡œ í™•ì¸)\n",
    "    engine.job()\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"ğŸš€ Finiary ìˆ˜ì§‘ê¸° ê°€ë™ ì¤‘ (ì£¼ê¸°: {UPDATE_INTERVAL_MINUTES}ë¶„)\")\n",
    "    print(f\"ğŸ“‚ ë°ì´í„°ë² ì´ìŠ¤: {DB_FILE}\")\n",
    "    print(\"ì¢…ë£Œí•˜ë ¤ë©´ Ctrl+Cë¥¼ ëˆ„ë¥´ì„¸ìš”.\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # 4. í”„ë¡œê·¸ë¨ì´ êº¼ì§€ì§€ ì•Šê²Œ ìœ ì§€\n",
    "    try:\n",
    "        while True:\n",
    "            time.sleep(1)\n",
    "    except (KeyboardInterrupt, SystemExit):\n",
    "        print(\"ğŸ›‘ ìˆ˜ì§‘ê¸°ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.\")\n",
    "        scheduler.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b7d23b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
